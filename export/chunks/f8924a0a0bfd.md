---
chunk_index: 1073
ref: "f8924a0a0bfd"
id: "f8924a0a0bfd0e6b8cd34098518ee1cc66a608b69a289f0750afd3491626c747"
slug: "mod-l1-146"
path: "/home/zack/dev/llmx/ingestor-core/src/handlers/mod.rs"
kind: "text"
lines: [1, 146]
token_estimate: 1078
content_sha256: "0ab0eafebdeef6a9c81be5b5265d3fa2d7730b0adfcc34847277a8aa4b92661a"
compacted: false
heading_path: []
symbol: null
address: null
asset_path: null
---

//! Core handlers for llmx operations.
//!
//! This module contains the business logic for indexing, searching, and managing
//! codebase indexes. It's designed to be used by both the CLI and MCP server.

mod storage;
mod types;

pub use storage::{IndexMetadata, IndexStore, Registry};
pub use types::*;

use crate::{ingest_files, search, FileInput, IngestOptions, SearchFilters};
use anyhow::{Context, Result};
use std::collections::HashSet;
use std::fs;
use std::path::{Path, PathBuf};

const DEFAULT_MAX_TOKENS: usize = 16000;

/// File extensions to include when indexing.
pub const ALLOWED_EXTENSIONS: &[&str] = &[
    // Rust
    "rs",
    // JavaScript/TypeScript
    "js", "ts", "tsx", "jsx", "mjs", "cjs",
    // Web
    "html", "css", "scss", "sass", "less",
    // Data
    "json", "yaml", "yml", "toml",
    // Documentation
    "md", "txt",
    // Python
    "py",
    // Go
    "go",
    // C/C++
    "c", "cpp", "cc", "cxx", "h", "hpp", "hxx",
    // Java
    "java",
    // Ruby
    "rb",
    // PHP
    "php",
    // Shell
    "sh", "bash", "zsh",
    // SQL
    "sql",
];

/// Handler for `llmx_index` tool: Create or update codebase indexes.
///
/// # Arguments
///
/// * `store` - Mutable reference to IndexStore
/// * `input` - Index input containing paths and options
///
/// # Behavior
///
/// 1. Recursively walks directories and reads files
/// 2. Filters by extension whitelist
/// 3. Checks for existing index by root path
/// 4. Creates new index or updates existing one
/// 5. Saves to disk and returns metadata
pub fn llmx_index_handler(store: &mut IndexStore, input: IndexInput) -> Result<IndexOutput> {
    let mut files = vec![];
    for path_str in &input.paths {
        let path = PathBuf::from(path_str);
        if path.is_dir() {
            walk_directory(&path, &mut files)?;
        } else if path.is_file() {
            read_file(&path, &mut files)?;
        }
    }

    let root_path = input.paths[0].clone();
    let existing_id = store.find_by_path(Path::new(&root_path));

    let options = IngestOptions {
        chunk_target_chars: input
            .options
            .as_ref()
            .and_then(|o| o.chunk_target_chars)
            .unwrap_or(4000),
        chunk_max_chars: 8000,
        max_file_bytes: input
            .options
            .as_ref()
            .and_then(|o| o.max_file_bytes)
            .unwrap_or(10 * 1024 * 1024),
        max_total_bytes: 50 * 1024 * 1024,
        max_chunks_per_file: 2000,
    };

    let mut index = ingest_files(files, options);
    let created = existing_id.is_none();

    #[cfg(feature = "embeddings")]
    {
        use crate::embeddings::generate_embeddings;
        let chunk_texts: Vec<&str> = index.chunks.iter().map(|c| c.content.as_str()).collect();
        let embeddings = generate_embeddings(&chunk_texts);
        index.embeddings = Some(embeddings);
        index.embedding_model = Some("hash-based-v1".to_string());
    }

    let index_id = store.save(index.clone(), root_path)?;

    Ok(IndexOutput {
        index_id,
        created,
        stats: IndexStatsOutput {
            total_files: index.stats.total_files,
            total_chunks: index.stats.total_chunks,
            avg_chunk_tokens: index.stats.avg_chunk_tokens,
        },
        warnings: index
            .warnings
            .iter()
            .map(|w| WarningOutput {
                path: w.path.clone(),
                code: w.code.clone(),
                message: w.message.clone(),
            })
            .collect(),
    })
}

/// Handler for `llmx_search` tool: Search indexed codebase with inline content.
///
/// Results include inline chunk content up to `max_tokens` (default: 16K).
/// When budget is exceeded, remaining chunks are returned in `truncated_ids`.
pub fn llmx_search_handler(store: &mut IndexStore, input: SearchInput) -> Result<SearchOutput> {
    let index = store.load(&input.index_id)?;

    let filters = input
        .filters
        .as_ref()
        .map(|f| SearchFilters {
            path_exact: None,
            path_prefix: f.path_prefix.clone(),
            kind: f.kind.as_ref().and_then(|k| parse_chunk_kind(k)),
            heading_prefix: f.heading_prefix.clone(),
            symbol_prefix: f.symbol_prefix.clone(),
        })
        .unwrap_or_default();