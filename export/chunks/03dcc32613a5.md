---
chunk_index: 52
ref: "03dcc32613a5"
id: "03dcc32613a5a6702168a425984bc091f59b792dba301b268111ce6180da9fba"
slug: "claude-model-selection-for-c--assistant"
path: "/home/zack/dev/llmx/claude_Model selection for current project_2026-01-17.md"
kind: "markdown"
lines: [309, 387]
token_estimate: 906
content_sha256: "cdcd3ffd2add44ab3700041f4d794cf0c96b9f6a70b8a8795bf298144d740fa9"
compacted: false
heading_path: ["Model selection for current project","Assistant"]
symbol: null
address: null
asset_path: null
---

## Assistant

The user is showing me feedback from Gemini that was based on the OLD Phase 6 spec (the one that used `ort` and was server-side). This feedback is now partially outdated because we've pivoted to Burn + WebGPU for browser deployment.

Let me analyze what's still relevant vs what needs to change:

**Still Relevant (architecture-agnostic):**
1. Tool Interface - keeping 4 tools, using `use_semantic` flag ✓
2. Error Handling - graceful degradation still needed
3. RRF Algorithm - same regardless of runtime
4. Token Budgeting - applies after fusion
5. Index Versioning / `embedding_model` field - still needed

**Now Outdated (due to Burn pivot):**
1. Binary Size 12MB limit - less relevant for browser (WASM + separate model weights)
2. `ureq` downloader - browser uses `fetch` + IndexedDB
3. `~/.llmx/models` path - browser uses IndexedDB cache
4. Arc<Mutex<IndexStore>> concerns - browser has different concurrency model
5. `cargo bench` baselines - need browser-specific benchmarks
6. `catch_unwind` for ONNX - Burn has different error handling

**Key insight:** This Gemini feedback was for a server-side MCP deployment. The llm.cat browser deployment has fundamentally different constraints:
- No filesystem (~/.llmx)
- No native threads (WASM single-threaded + async)
- WebGPU async model
- CDN + IndexedDB for model weights
- Different performance targets (100ms vs 50ms per embedding)

I should help Zack understand what's salvageable and what needs to be thrown out.Good catch. That Gemini feedback is based on the **old server-side spec** (`ort`, `~/.llmx`, `ureq` downloader). Half of it is now wrong for browser deployment.

**Still valid:**

| Area | Gemini Feedback | Status |
|------|-----------------|--------|
| Tool Interface | Keep 4 tools, use `use_semantic` flag | ✓ Still applies |
| RRF Algorithm | k=60, formula correct | ✓ Runtime-agnostic |
| Token Budgeting | Apply after fusion, not before | ✓ Still applies |
| Index Versioning | `embedding_model` field for invalidation | ✓ Still applies |
| Error Handling | Graceful degradation to BM25 | ✓ Still applies |

**Now wrong (browser context):**

| Area | Gemini Said | Reality for llm.cat |
|------|-------------|---------------------|
| Binary Size | 12MB limit, don't embed models | WASM + separate weights, different size math |
| Model Storage | `~/.llmx/models/` | IndexedDB cache (no filesystem) |
| Downloader | `ureq` crate | Browser `fetch()` API |
| Concurrency | `Arc<Mutex<>>`, tokio yield | WASM single-threaded, all async |
| Panic Handling | `catch_unwind` for ORT | Burn has different error model |
| Benchmarks | `cargo bench` baselines | Need browser perf.now() benchmarks |

**Key architectural difference:**

Gemini assumed MCP server running natively. llm.cat is browser-only:
- No `~/.llmx` directory
- No native threads
- No `ureq`/`reqwest` (use `fetch`)
- WebGPU is async (can't block)
- Model weights via CDN → IndexedDB, not filesystem

**What to keep from Gemini's Day 1 checklist:**

```diff
- [ ] Run `cargo bench` on current master
+ [ ] Establish browser performance baseline (manual timing)

- [ ] Implement `ureq` downloader
+ [ ] Implement fetch + IndexedDB caching

- [ ] Test offline graceful failure  
+ [ ] Test WebGPU unavailable → CPU fallback → hash fallback

  [ ] Tokenizer uses correct tokenizer.json for model ✓ (still applies)
  [ ] embedding_model mismatch triggers warning ✓ (still applies)
  [ ] Integration test: index → semantic search → cached search ✓ (still applies)
```

Want me to update P6_DIRECTIONS.md with a corrected Day 1 checklist that accounts for browser constraints?