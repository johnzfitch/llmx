---
chunk_index: 178
ref: "2e7f009df6b8"
id: "2e7f009df6b8acd450e2e142b4f49670f88a4f35de170e9aab45e4cd92f2d7ef"
slug: "cutting-edge-enhancements--the-problem-with-dense-embeddings"
path: "/home/zack/dev/llmx/docs/CUTTING_EDGE_ENHANCEMENTS.md"
kind: "markdown"
lines: [20, 25]
token_estimate: 62
content_sha256: "499a3e8b0aab6effe48f9b0ad1992f53c10746d37d1c9e47d5ffd0393ab5475c"
compacted: false
heading_path: ["Cutting-Edge Enhancements for Phases 1-4","1. Learned Sparse Retrieval (SPLADE) ðŸš€","The Problem with Dense Embeddings"]
symbol: null
address: null
asset_path: null
---

### The Problem with Dense Embeddings
**Embeddings are slow**: Need to compute dot products with all chunks
- 10K chunks = 10K dot products per query
- Even with HNSW, still slower than inverted index
- High memory usage (384D or 768D per chunk)