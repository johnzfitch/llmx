---
chunk_index: 1013
ref: "7e5fa79be267"
id: "7e5fa79be267068477c0f9872336ee820d16412558231099a39a88e43f312090"
slug: "llmx-v5-design-prompt--questions-for-review"
path: "/home/zack/dev/llmx/docs/llmx-v5-design-prompt.md"
kind: "markdown"
lines: [167, 201]
token_estimate: 317
content_sha256: "4fdab920047b31b5f9036d1a13649e42a3e74a797a899a9600cb0bb804cee302"
compacted: false
heading_path: ["LLMX v5 Format Redesign - External Review Prompt","Questions for Review"]
symbol: null
address: null
asset_path: null
---

## Questions for Review

1. **Which option (A-E) best balances human readability and LLM efficiency?**

2. **What's the optimal file count?** Single file vs ~5 bundles vs many small files?

3. **How should token counts be displayed?** In filenames (`auth_2k.md`), in headers, in manifest only?

4. **Should the manifest be a separate file or embedded in README?**

5. **For versioned projects, is delta compression worth the complexity?**

6. **What metadata is actually necessary per chunk/file?**
   - Current: ref, path_i, kind_i, start_line, end_line, tokens, label (7 fields)
   - Minimum viable: ???

7. **Are there existing formats we should learn from?**
   - Jupyter notebooks (.ipynb)
   - Web archives (WARC)
   - Literate programming (noweb, org-mode)
   - Static site generators (Hugo, Jekyll)
   - Other?

8. **How do RAG/retrieval systems affect the design?**
   - Small chunks (512 tokens) are better for vector search
   - But LLM direct consumption wants larger coherent sections
   - Can one format serve both?

9. **What's the right balance between compression and readability?**
   - Maximum compression: custom DSL, binary format
   - Maximum readability: verbose markdown
   - Sweet spot: ???

10. **Any novel approaches we haven't considered?**