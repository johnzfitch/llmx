---
chunk_index: 424
ref: "27e9422ba52f"
id: "27e9422ba52f845f57fe4890c879b60cc49a623bc263075a0c27c7c7c1e0c521"
slug: "phase6-status--2-tokenizer-in-wasm"
path: "/home/zack/dev/llmx/docs/PHASE6_STATUS.md"
kind: "markdown"
lines: [148, 176]
token_estimate: 197
content_sha256: "5fbe8258d80f46ff9cf460f1a0cd0e62cd7740c80c95c8d600ba1a08928ac630"
compacted: false
heading_path: ["Phase 6 Implementation Status","ðŸš§ Blocked Components","2. Tokenizer in WASM"]
symbol: null
address: null
asset_path: null
---

### 2. Tokenizer in WASM

**Issue:** `tokenizers` crate depends on `onig` (Oniguruma regex), which doesn't compile to WASM.

**Why This Blocks:**
- Cannot tokenize text in browser
- Cannot prepare input for model
- Pre-processing step missing

**Potential Solutions:**

1. **Use WASM-compatible tokenizer** (Recommended)
   ```rust
   // Options:
   // - esaxx_rs (WASM-compatible BPE)
   // - Custom WordPiece tokenizer in pure Rust
   // - Load pre-tokenized vocab and implement simple tokenizer
   ```

2. **Pre-tokenize on server**
   - Generate token IDs server-side
   - Send token arrays to WASM
   - Trade-off: Requires server roundtrip

3. **JavaScript tokenizer**
   - Use transformers.js tokenizer
   - Pass tokens to Rust via wasm-bindgen
   - Trade-off: Mixed language stack