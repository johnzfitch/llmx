---
chunk_index: 1083
ref: "ae09f0038ffb"
id: "ae09f0038ffb29a638bdafd3a6833f93bac0dbb52c992d8d74da049dcc458601"
slug: "lib-l1-124"
path: "/home/zack/dev/llmx/ingestor-core/src/lib.rs"
kind: "text"
lines: [1, 124]
token_estimate: 1016
content_sha256: "064657f3cad99b1b320ed3c121b3aa2ce849d1eaf10fae41da54e3dd9ed3600c"
compacted: false
heading_path: []
symbol: null
address: null
asset_path: null
---

mod chunk;
mod export;
mod index;
mod model;
pub mod util;

// Handlers module is always available (used by both CLI and MCP)
#[cfg(any(feature = "cli", feature = "mcp"))]
pub mod handlers;

#[cfg(feature = "mcp")]
pub mod mcp;

#[cfg(feature = "embeddings")]
pub mod embeddings;

pub use crate::export::{export_chunks, export_llm, export_manifest_json, export_zip};
pub use crate::index::{build_inverted_index, compute_stats, list_outline, list_symbols, search_index};
#[cfg(feature = "embeddings")]
pub use crate::index::{hybrid_search, vector_search};
pub use crate::model::*;
use crate::util::{build_chunk_refs, detect_kind, sha256_hex};
use std::collections::BTreeMap;

pub fn ingest_files(mut files: Vec<FileInput>, options: IngestOptions) -> IndexFile {
    files.sort_by(|a, b| a.path.cmp(&b.path));

    let mut warnings = Vec::new();
    let mut total_bytes = 0usize;
    let mut file_metas = Vec::new();
    let mut chunks = Vec::new();

    for file in files {
        let path = file.path;
        let data = file.data;
        let mtime_ms = file.mtime_ms;
        let fingerprint_sha256 = file.fingerprint_sha256;
        if total_bytes + data.len() > options.max_total_bytes {
            warnings.push(IngestWarning {
                path: path.clone(),
                code: "max_total_bytes".to_string(),
                message: "Total size limit exceeded; file skipped.".to_string(),
            });
            continue;
        }
        if data.len() > options.max_file_bytes {
            warnings.push(IngestWarning {
                path: path.clone(),
                code: "max_file_bytes".to_string(),
                message: "File size limit exceeded; file skipped.".to_string(),
            });
            continue;
        }
        total_bytes += data.len();
        let kind = detect_kind(&path);
        let file_hash = sha256_hex(&data);
        let bytes_len = data.len();

        let (line_count, mut file_chunks) = if kind == ChunkKind::Image {
            let mut chunks = chunk::chunk_file(&path, "", kind, &options);
            for chunk in &mut chunks {
                chunk.asset_path = Some(format!("images/{}", sanitize_zip_path(&path)));
            }
            (1usize, chunks)
        } else {
            let text = match String::from_utf8(data) {
                Ok(text) => text,
                Err(_) => {
                    warnings.push(IngestWarning {
                        path: path.clone(),
                        code: "utf8".to_string(),
                        message: "File is not valid UTF-8; file skipped.".to_string(),
                    });
                    continue;
                }
            };
            let line_count = text.lines().count().max(1);
            (line_count, chunk::chunk_file(&path, &text, kind, &options))
        };

        if file_chunks.len() > options.max_chunks_per_file {
            warnings.push(IngestWarning {
                path: path.clone(),
                code: "max_chunks_per_file".to_string(),
                message: "Chunk limit exceeded; file truncated.".to_string(),
            });
            file_chunks.truncate(options.max_chunks_per_file);
        }
        chunks.extend(file_chunks);
        file_metas.push(FileMeta {
            path,
            kind,
            bytes: bytes_len,
            sha256: file_hash,
            line_count,
            mtime_ms,
            fingerprint_sha256,
        });
    }

    chunks.sort_by(|a, b| match a.path.cmp(&b.path) {
        std::cmp::Ordering::Equal => a.start_line.cmp(&b.start_line),
        other => other,
    });

    let chunk_refs = build_chunk_refs(&chunks);
    let inverted_index = build_inverted_index(&chunks);
    let stats = compute_stats(&file_metas, &chunks);
    let index_id = compute_index_id(&file_metas);

    IndexFile {
        version: 1,
        index_id,
        files: file_metas,
        chunks,
        chunk_refs,
        inverted_index,
        stats,
        warnings,
        embeddings: None,
        embedding_model: None,
    }
}