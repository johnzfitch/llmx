---
chunk_index: 688
ref: "f18f9659ed6a"
id: "f18f9659ed6a8ca3eb3d60ae5e4fd9d4976aa92b61bcb7d59e137c120958093f"
slug: "phase-5-directions--1-embedding-generation-pipeline"
path: "/home/zack/dev/llmx/docs/PHASE_5_DIRECTIONS.md"
kind: "markdown"
lines: [16, 44]
token_estimate: 236
content_sha256: "4fbb5df14f27e74836d5de2768af591491e935eac01be86c220447e0b5df178a"
compacted: false
heading_path: ["Phase 5: Semantic Search & Embeddings Integration","Primary Objectives","1. Embedding Generation Pipeline"]
symbol: null
address: null
asset_path: null
---

### 1. Embedding Generation Pipeline
**Goal**: Generate and store embeddings for all indexed chunks

**Tasks**:
- [ ] Add embedding model integration (options: local ONNX, OpenAI, Anthropic)
- [ ] Implement batched embedding generation to optimize API calls
- [ ] Store embeddings in index format (consider binary format for size)
- [ ] Add embedding version tracking for cache invalidation

**Model Selection Criteria**:
```rust
// Priority order for embedding providers
1. Local ONNX (e5-small-v2, all-MiniLM-L6) - fast, free, private
2. Voyage AI - optimized for code, excellent quality
3. OpenAI text-embedding-3-small - good balance
4. Claude embeddings - when available
```

**Storage Schema**:
```rust
pub struct ChunkWithEmbedding {
    pub chunk_id: String,
    pub content: String,
    pub embedding: Vec<f32>,  // 384 or 768 dimensions
    pub embedding_model: String,  // track model version
    pub embedding_timestamp: u64,
}
```