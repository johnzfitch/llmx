---
chunk_index: 1363
ref: "1be8a1edf3e7"
id: "1be8a1edf3e7a3a32082c898d88b541d3d5ceaf6c64d4bf9d8d948c7e984ab38"
slug: "tokenizer--normalizer"
path: "/home/zack/dev/llmx/web/models/tokenizer.json"
kind: "json"
lines: [1, 30684]
token_estimate: 33
content_sha256: "e6601b98c31c748a37131be6d4e93f512381124fb27b385db4fcac4ec545acfa"
compacted: false
heading_path: ["normalizer"]
symbol: "normalizer"
address: "$.normalizer"
asset_path: null
---

{
  "clean_text": true,
  "handle_chinese_chars": true,
  "lowercase": true,
  "strip_accents": null,
  "type": "BertNormalizer"
}