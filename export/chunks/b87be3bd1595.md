---
chunk_index: 1085
ref: "b87be3bd1595"
id: "b87be3bd1595c92ac67a74ad686bd31eef2a6e4756440900b86fc87b53506fbb"
slug: "lib-l244-362"
path: "/home/zack/dev/llmx/ingestor-core/src/lib.rs"
kind: "text"
lines: [244, 362]
token_estimate: 1029
content_sha256: "3d713bb5fa7792d76dd34d49a1dbc2a5a995881e87f4a7641cfdaa1c21aaaa71"
compacted: false
heading_path: []
symbol: null
address: null
asset_path: null
---

pub fn update_index_selective(
    prev: IndexFile,
    files: Vec<FileInput>,
    keep_paths: Vec<String>,
    options: IngestOptions,
) -> IndexFile {
    let mut prev_map: BTreeMap<String, (FileMeta, Vec<Chunk>)> = BTreeMap::new();
    let mut chunk_map: BTreeMap<String, Vec<Chunk>> = BTreeMap::new();
    for chunk in prev.chunks {
        chunk_map.entry(chunk.path.clone()).or_default().push(chunk);
    }
    for file in prev.files {
        if let Some(chunks) = chunk_map.remove(&file.path) {
            prev_map.insert(file.path.clone(), (file, chunks));
        }
    }

    let mut warnings = Vec::new();
    let mut file_metas = Vec::new();
    let mut chunks = Vec::new();

    let mut keep_paths_sorted = keep_paths;
    keep_paths_sorted.sort();
    keep_paths_sorted.dedup();

    for path in keep_paths_sorted {
        if let Some((meta, existing_chunks)) = prev_map.get(&path) {
            file_metas.push(meta.clone());
            chunks.extend(existing_chunks.clone());
        }
    }

    let mut new_files = files;
    new_files.sort_by(|a, b| a.path.cmp(&b.path));

    let mut total_bytes = 0usize;
    for file in new_files {
        let path = file.path;
        let data = file.data;
        let mtime_ms = file.mtime_ms;
        let fingerprint_sha256 = file.fingerprint_sha256;
        if total_bytes + data.len() > options.max_total_bytes {
            warnings.push(IngestWarning {
                path: path.clone(),
                code: "max_total_bytes".to_string(),
                message: "Total size limit exceeded; file skipped.".to_string(),
            });
            continue;
        }
        if data.len() > options.max_file_bytes {
            warnings.push(IngestWarning {
                path: path.clone(),
                code: "max_file_bytes".to_string(),
                message: "File size limit exceeded; file skipped.".to_string(),
            });
            continue;
        }
        total_bytes += data.len();

        let kind = detect_kind(&path);
        let file_hash = sha256_hex(&data);
        let bytes_len = data.len();

        if let Some((meta, existing_chunks)) = prev_map.get(&path) {
            if meta.sha256 == file_hash {
                file_metas.push(meta.clone());
                chunks.extend(existing_chunks.clone());
                continue;
            }
        }

        let (line_count, mut file_chunks) = if kind == ChunkKind::Image {
            let mut chunks = chunk::chunk_file(&path, "", kind, &options);
            for chunk in &mut chunks {
                chunk.asset_path = Some(format!("images/{}", sanitize_zip_path(&path)));
            }
            (1usize, chunks)
        } else {
            let text = match String::from_utf8(data) {
                Ok(text) => text,
                Err(_) => {
                    warnings.push(IngestWarning {
                        path: path.clone(),
                        code: "utf8".to_string(),
                        message: "File is not valid UTF-8; file skipped.".to_string(),
                    });
                    continue;
                }
            };
            let line_count = text.lines().count().max(1);
            (line_count, chunk::chunk_file(&path, &text, kind, &options))
        };

        if file_chunks.len() > options.max_chunks_per_file {
            warnings.push(IngestWarning {
                path: path.clone(),
                code: "max_chunks_per_file".to_string(),
                message: "Chunk limit exceeded; file truncated.".to_string(),
            });
            file_chunks.truncate(options.max_chunks_per_file);
        }
        chunks.extend(file_chunks);
        file_metas.push(FileMeta {
            path,
            kind,
            bytes: bytes_len,
            sha256: file_hash,
            line_count,
            mtime_ms,
            fingerprint_sha256,
        });
    }

    file_metas.sort_by(|a, b| a.path.cmp(&b.path));
    chunks.sort_by(|a, b| match a.path.cmp(&b.path) {
        std::cmp::Ordering::Equal => a.start_line.cmp(&b.start_line),
        other => other,
    });