---
chunk_index: 1084
ref: "477a665cdaf0"
id: "477a665cdaf086ded78d061073db618198ad6fb9f33f77ca3c37f9c16949e908"
slug: "lib-l125-243"
path: "/home/zack/dev/llmx/ingestor-core/src/lib.rs"
kind: "text"
lines: [125, 243]
token_estimate: 1034
content_sha256: "d5e4d05b9274df57d0801dac57f6951061dac936f54a264a6e6d9b62054c74ae"
compacted: false
heading_path: []
symbol: null
address: null
asset_path: null
---

pub fn update_index(prev: IndexFile, files: Vec<FileInput>, options: IngestOptions) -> IndexFile {
    let mut prev_map: BTreeMap<String, (FileMeta, Vec<Chunk>)> = BTreeMap::new();
    let mut chunk_map: BTreeMap<String, Vec<Chunk>> = BTreeMap::new();
    for chunk in prev.chunks {
        chunk_map.entry(chunk.path.clone()).or_default().push(chunk);
    }
    for file in prev.files {
        if let Some(chunks) = chunk_map.remove(&file.path) {
            prev_map.insert(file.path.clone(), (file, chunks));
        }
    }

    let mut new_files = files;
    new_files.sort_by(|a, b| a.path.cmp(&b.path));

    let mut warnings = Vec::new();
    let mut file_metas = Vec::new();
    let mut chunks = Vec::new();
    let mut total_bytes = 0usize;

    for file in new_files {
        let path = file.path;
        let data = file.data;
        let mtime_ms = file.mtime_ms;
        let fingerprint_sha256 = file.fingerprint_sha256;
        if total_bytes + data.len() > options.max_total_bytes {
            warnings.push(IngestWarning {
                path: path.clone(),
                code: "max_total_bytes".to_string(),
                message: "Total size limit exceeded; file skipped.".to_string(),
            });
            continue;
        }
        if data.len() > options.max_file_bytes {
            warnings.push(IngestWarning {
                path: path.clone(),
                code: "max_file_bytes".to_string(),
                message: "File size limit exceeded; file skipped.".to_string(),
            });
            continue;
        }
        total_bytes += data.len();
        let kind = detect_kind(&path);
        let file_hash = sha256_hex(&data);
        let bytes_len = data.len();
        if let Some((meta, existing_chunks)) = prev_map.get(&path) {
            if meta.sha256 == file_hash {
                file_metas.push(meta.clone());
                chunks.extend(existing_chunks.clone());
                continue;
            }
        }

        let (line_count, mut file_chunks) = if kind == ChunkKind::Image {
            let mut chunks = chunk::chunk_file(&path, "", kind, &options);
            for chunk in &mut chunks {
                chunk.asset_path = Some(format!("images/{}", sanitize_zip_path(&path)));
            }
            (1usize, chunks)
        } else {
            let text = match String::from_utf8(data) {
                Ok(text) => text,
                Err(_) => {
                    warnings.push(IngestWarning {
                        path: path.clone(),
                        code: "utf8".to_string(),
                        message: "File is not valid UTF-8; file skipped.".to_string(),
                    });
                    continue;
                }
            };
            let line_count = text.lines().count().max(1);
            (line_count, chunk::chunk_file(&path, &text, kind, &options))
        };

        if file_chunks.len() > options.max_chunks_per_file {
            warnings.push(IngestWarning {
                path: path.clone(),
                code: "max_chunks_per_file".to_string(),
                message: "Chunk limit exceeded; file truncated.".to_string(),
            });
            file_chunks.truncate(options.max_chunks_per_file);
        }
        chunks.extend(file_chunks);
        file_metas.push(FileMeta {
            path,
            kind,
            bytes: bytes_len,
            sha256: file_hash,
            line_count,
            mtime_ms,
            fingerprint_sha256,
        });
    }

    chunks.sort_by(|a, b| match a.path.cmp(&b.path) {
        std::cmp::Ordering::Equal => a.start_line.cmp(&b.start_line),
        other => other,
    });

    let chunk_refs = build_chunk_refs(&chunks);
    let inverted_index = build_inverted_index(&chunks);
    let stats = compute_stats(&file_metas, &chunks);
    let index_id = compute_index_id(&file_metas);

    IndexFile {
        version: 1,
        index_id,
        files: file_metas,
        chunks,
        chunk_refs,
        inverted_index,
        stats,
        warnings,
        embeddings: None,
        embedding_model: None,
    }
}